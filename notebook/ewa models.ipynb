{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed645441-e4b5-4d9d-a3e6-9f10be38615b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"../src/public/models/\"\n",
    "\n",
    "FFT_BINS = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a138fcfd-fc1c-4cb3-a6f8-efb51b39fe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5a65583-3e77-4977-ad8e-f48979ef7aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ewa(new, old, alpha):\n",
    "    return new * alpha + old * (1 - alpha)\n",
    "\n",
    "def scaleToAsymptote(x, asymptote, threshold):\n",
    "    return torch.minimum(torch.tensor(asymptote), x * asymptote/threshold)\n",
    "\n",
    "def pw_linear(x, breakpoints_values):\n",
    "    # Extract x_i and y_i from input\n",
    "    xp, yp = zip(*breakpoints_values)  # unzip into two lists\n",
    "    xp = torch.tensor(xp, dtype=x.dtype, device=x.device)\n",
    "    yp = torch.tensor(yp, dtype=x.dtype, device=x.device)\n",
    "\n",
    "    # Clamp x to the range\n",
    "    x_clamped = torch.clamp(x, xp[0], xp[-1])\n",
    "\n",
    "    # Find the interval index i such that xp[i] <= x < xp[i+1]\n",
    "    indices = torch.bucketize(x_clamped, xp, right=False)\n",
    "    indices = torch.clamp(indices, 1, len(xp) - 1)\n",
    "\n",
    "    x0 = xp[indices - 1]\n",
    "    x1 = xp[indices]\n",
    "    y0 = yp[indices - 1]\n",
    "    y1 = yp[indices]\n",
    "\n",
    "    # Linear interpolation\n",
    "    t = (x_clamped - x0) / (x1 - x0 + 1e-8)\n",
    "    y = y0 + t * (y1 - y0)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e0b9749-d26f-4882-8b13-be93b58c58ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmoothedPeak(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x, h):   \n",
    "        peak = (x**1.5).sum(axis=1) * 10\n",
    "        h_new = ewa(peak, h, 0.025)\n",
    "        y = torch.tanh(h_new**2 * 2) \n",
    "        return y, h_new\n",
    "\n",
    "\n",
    "# Example usage and export\n",
    "model = SmoothedPeak()\n",
    "\n",
    "# Dummy inputs: batch size 1\n",
    "x = torch.randn(1, FFT_BINS)\n",
    "h = torch.zeros(1, 1)\n",
    "\n",
    "# Export to ONNX\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    (x, h),\n",
    "    MODEL_PATH + \"smooth_peak.onnx\",\n",
    "    input_names=[\"x\", \"h\"],\n",
    "    output_names=[\"output\", \"h\"],\n",
    "    dynamic_axes={\n",
    "        \"x\": {0: \"batch\"},\n",
    "        \"h\": {0: \"batch\"},\n",
    "        \"output\": {0: \"batch\"},\n",
    "    },\n",
    "    opset_version=12,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a56d2d3-d0e7-4148-9121-3bc4e317f228",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2812/1863610842.py:10: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  y = torch.clamp(h_binary_new, torch.tensor(0), torch.tensor(1))\n"
     ]
    }
   ],
   "source": [
    "class Playing(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x, h_signal, h_binary):\n",
    "        signal = (x.max(axis=-1)[0] != 0) * 1\n",
    "        h_signal_new = ewa(signal, h_signal, 0.01)\n",
    "        binary = (h_signal_new > 0.15) * 1.1 - 0.05\n",
    "        h_binary_new = ewa(binary, h_binary, 0.05)\n",
    "        y = torch.clamp(h_binary_new, torch.tensor(0), torch.tensor(1))\n",
    "\n",
    "        return y, h_signal_new, h_binary_new\n",
    "\n",
    "\n",
    "# Example usage and export\n",
    "model = Playing()\n",
    "\n",
    "# Dummy inputs: batch size 1\n",
    "x = torch.randn(1, FFT_BINS)\n",
    "h = torch.zeros(1, 1)\n",
    "# Export to ONNX\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    (x, h, h),\n",
    "    MODEL_PATH + \"playing.onnx\",\n",
    "    input_names=[\"x\", \"h_signal\", \"h_binary\"],\n",
    "    output_names=[\"output\", \"h_signal\", \"h_binary\"],\n",
    "    dynamic_axes={\n",
    "        \"x\": {0: \"batch\"},\n",
    "        \"h_signal\": {0: \"batch\"},\n",
    "        \"h_binary\": {0: \"batch\"},\n",
    "        \"output\": {0: \"batch\"},\n",
    "    },\n",
    "    opset_version=12,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "250b5052-2a4d-405e-b2c0-0aa48b7b58f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2812/2319570008.py:16: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  torch.tensor(0), torch.tensor(2/scale))\n",
      "/tmp/ipykernel_2812/4071428356.py:10: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  xp = torch.tensor(xp, dtype=x.dtype, device=x.device)\n",
      "/tmp/ipykernel_2812/4071428356.py:11: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  yp = torch.tensor(yp, dtype=x.dtype, device=x.device)\n",
      "/tmp/ipykernel_2812/4071428356.py:18: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.\n",
      "  indices = torch.clamp(indices, 1, len(xp) - 1)\n"
     ]
    }
   ],
   "source": [
    "class Momentum(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x, h_peak, h_silence, h):\n",
    "        peak = (x**0.1).sum(axis=-1) * 0.5\n",
    "        h_peak_new = ewa(peak, h_peak, 0.4)\n",
    "        is_prominent = (h_peak_new > 0.65) * 1\n",
    "        \n",
    "        silence = (x.max(axis=-1)[0] == 0) * 1\n",
    "        h_silence_new = ewa(silence, h_silence, 0.01)\n",
    "        is_silent = (h_silence_new > 0.85) * 1\n",
    "\n",
    "        scale = 0.1\n",
    "        h_new = torch.clamp(h + is_prominent * 1e-2 - is_silent * 2e-1 - 2e-3,\n",
    "                            torch.tensor(0), torch.tensor(2/scale))\n",
    "        s = h_new * scale\n",
    "        y = pw_linear(s, [(0, 0), (0.3, 0.4), (0.7, 0.6), (1, 0.9), (2, 1)])\n",
    "        return y, h_peak_new, h_silence_new, h_new\n",
    "\n",
    "\n",
    "# Example usage and export\n",
    "model = Momentum()\n",
    "\n",
    "# Dummy inputs: batch size 1\n",
    "x = torch.randn(1, FFT_BINS)\n",
    "h = torch.zeros(1, 1)\n",
    "# Export to ONNX\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    (x, h, h, h),\n",
    "    MODEL_PATH + \"momentum.onnx\",\n",
    "    input_names=[\"x\", \"h_peak\", \"h_silence\", \"h\"],\n",
    "    output_names=[\"output\", \"h_peak\", \"h_silence\", \"h\"],\n",
    "    dynamic_axes={\n",
    "        \"x\": {0: \"batch\"},\n",
    "        \"h\": {0: \"batch\"},\n",
    "        \"h_peak\": {0: \"batch\"},\n",
    "        \"h_silence\": {0: \"batch\"},\n",
    "        \"output\": {0: \"batch\"},\n",
    "    },\n",
    "    opset_version=12,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a75bf06-93ea-4b75-81ea-a67de7d5f0cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
